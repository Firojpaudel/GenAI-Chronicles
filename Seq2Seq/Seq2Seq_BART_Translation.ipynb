{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiyLwkGPpr9sQwJ24Doeew",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f03655c996104c8e9ecc47a8ab5f25ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a27b727703c94cb9bff330ab80bdc87d",
              "IPY_MODEL_3e6fce74bcdb4e269071695d53241892",
              "IPY_MODEL_58735fe38e944ba6afbfb30868235cbb"
            ],
            "layout": "IPY_MODEL_5e5934a15ebd4586a034eaef8f2f5900"
          }
        },
        "a27b727703c94cb9bff330ab80bdc87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9215ebc1485430f83a9977b29ea12d4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2c2be4595d2b419c8e99612a94341b0a",
            "value": "Map:‚Äá100%"
          }
        },
        "3e6fce74bcdb4e269071695d53241892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_546a59aaa7bd4ffd9cdc255794f39c09",
            "max": 19,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b0e7332d4d44256ac39a7e3b188eeda",
            "value": 19
          }
        },
        "58735fe38e944ba6afbfb30868235cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74bd20d3b88a45fa94a7c9d457badf52",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0716939ec1e74b99bbd4c7798c327871",
            "value": "‚Äá19/19‚Äá[00:00&lt;00:00,‚Äá290.44‚Äáexamples/s]"
          }
        },
        "5e5934a15ebd4586a034eaef8f2f5900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9215ebc1485430f83a9977b29ea12d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c2be4595d2b419c8e99612a94341b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "546a59aaa7bd4ffd9cdc255794f39c09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b0e7332d4d44256ac39a7e3b188eeda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74bd20d3b88a45fa94a7c9d457badf52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0716939ec1e74b99bbd4c7798c327871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Firojpaudel/GenAI-Chronicles/blob/main/Seq2Seq/Seq2Seq_BART_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **mBART**: *As a Translator* `(Eng-Nep)`\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "eKpOkUkXskYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before, I implemented the BART as a summarizer. Now, its time to use it as a language translator.\n",
        "\n",
        "Will be trying to set up English to Nepali translation using `facebook/mbart-large-50-many-to-many-mmt` model from Hugging Face.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "oyhZxWSuuZ_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "\n",
        "model_name= \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "\n",
        "tokenizer= MBart50TokenizerFast.from_pretrained(model_name)\n",
        "model= MBartForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "NvKwooEOvHrl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.src_lang = \"en_XX\"\n",
        "target_lang= \"ne_NP\""
      ],
      "metadata": {
        "id": "NQw5OXFWw_fm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(text):\n",
        "  inputs= tokenizer(text, return_tensors=\"pt\").to('cpu')\n",
        "\n",
        "  translated_tokens= model.generate(\n",
        "      **inputs,\n",
        "      forced_bos_token_id= tokenizer.lang_code_to_id[target_lang]\n",
        "  )\n",
        "\n",
        "  return tokenizer.decode(translated_tokens[0], skip_special_tokens= True)"
      ],
      "metadata": {
        "id": "U676pov_x-4P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_text = \"Welcome to the notebook file!\"\n",
        "\n",
        "nep_translation= translate(eng_text)\n",
        "\n",
        "print(nep_translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb-UuvV2y7z2",
        "outputId": "08df408a-0d32-43d8-b8f3-b89e08ccaad1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡§®‡•ã‡§ü‡§¨‡•Å‡§ï ‡§´‡§æ‡§á‡§≤‡§Æ‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§õ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well its working as intended but what if we want to fine-tune the model further?"
      ],
      "metadata": {
        "id": "ogCVZjgfzMiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "okay, so I have like curated a very small csv file that has gen-z english with its appropriate Nepali translations. Now, lets finetune this."
      ],
      "metadata": {
        "id": "Q6-MAkzrzgBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "UO4OHvJu84sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df= pd.read_csv(\"/content/low_key.csv\")\n",
        "df.columns= df.columns.str.strip()\n",
        "print(df.columns)\n",
        "\n",
        "## Converting the dataframe to Hugging Face Dataset\n",
        "\n",
        "dataset = Dataset.from_pandas(df)\n",
        "print(dataset.features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcLMWfGg7yo3",
        "outputId": "d441d711-e06a-4b27-9218-7da1a2ef40ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['english', 'nepali'], dtype='object')\n",
            "{'english': Value(dtype='string', id=None), 'nepali': Value(dtype='string', id=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= MBart50TokenizerFast.from_pretrained(model_name, src_lang= 'en_XX', tgt_lang=\"ne_NP\")"
      ],
      "metadata": {
        "id": "qTauOnPm_MFP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Preprocessing the Dataset:\n",
        "\n",
        "def preprocess_func(examples):\n",
        "  inputs = [ex for ex in examples['english']]\n",
        "  targets = [ex for ex in examples['nepali']]\n",
        "  model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding= 'max_length')\n",
        "\n",
        "  # Tokenize targets with the `text_target` keyword argument\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "      labels = tokenizer(targets, max_length=128, truncation=True, padding= 'max_length')\n",
        "\n",
        "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "  return model_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_func, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "f03655c996104c8e9ecc47a8ab5f25ae",
            "a27b727703c94cb9bff330ab80bdc87d",
            "3e6fce74bcdb4e269071695d53241892",
            "58735fe38e944ba6afbfb30868235cbb",
            "5e5934a15ebd4586a034eaef8f2f5900",
            "c9215ebc1485430f83a9977b29ea12d4",
            "2c2be4595d2b419c8e99612a94341b0a",
            "546a59aaa7bd4ffd9cdc255794f39c09",
            "9b0e7332d4d44256ac39a7e3b188eeda",
            "74bd20d3b88a45fa94a7c9d457badf52",
            "0716939ec1e74b99bbd4c7798c327871"
          ]
        },
        "id": "kNogzGC_8rji",
        "outputId": "5d83b18d-d448-4ec7-cfc9-5ef186f5e56d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/19 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f03655c996104c8e9ecc47a8ab5f25ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "import torch\n",
        "##@ Setting up the training args\n",
        "\n",
        "training_args= TrainingArguments(\n",
        "    output_dir= './results',\n",
        "    eval_strategy= 'epoch',\n",
        "    learning_rate= 2e-5,\n",
        "    per_device_train_batch_size= 4,\n",
        "    per_device_eval_batch_size= 4,\n",
        "    logging_steps= 5,\n",
        "    weight_decay = 0.01,\n",
        "    num_train_epochs=30,\n",
        "    fp16= torch.cuda.is_available()\n",
        ")"
      ],
      "metadata": {
        "id": "o5iignWL9-N3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model= model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NASajwN9A2XI",
        "outputId": "0e9b9539-436e-4383-a759-b2edec5ce68e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-f4a01ab80684>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "berRtZgwDc2w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TGRlhl3iBadg",
        "outputId": "588c3808-08ec-4cb1-c365-4f6541a30407"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfirojpaudel\u001b[0m (\u001b[33mfirojpaudel-madan-bhandari-memorial-college\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250108_092703-6x950blu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/firojpaudel-madan-bhandari-memorial-college/huggingface/runs/6x950blu' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/firojpaudel-madan-bhandari-memorial-college/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/firojpaudel-madan-bhandari-memorial-college/huggingface' target=\"_blank\">https://wandb.ai/firojpaudel-madan-bhandari-memorial-college/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/firojpaudel-madan-bhandari-memorial-college/huggingface/runs/6x950blu' target=\"_blank\">https://wandb.ai/firojpaudel-madan-bhandari-memorial-college/huggingface/runs/6x950blu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 02:25, Epoch 30/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>11.837700</td>\n",
              "      <td>11.309142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>10.874500</td>\n",
              "      <td>10.280623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>10.106000</td>\n",
              "      <td>9.661011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>9.517000</td>\n",
              "      <td>9.078266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>8.940800</td>\n",
              "      <td>8.493481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>8.370600</td>\n",
              "      <td>7.914397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>7.806200</td>\n",
              "      <td>7.351004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>7.253600</td>\n",
              "      <td>6.798064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>6.714700</td>\n",
              "      <td>6.259949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>6.187100</td>\n",
              "      <td>5.740569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>5.682200</td>\n",
              "      <td>5.244140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>5.195300</td>\n",
              "      <td>4.770314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>4.738200</td>\n",
              "      <td>4.326595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>4.301600</td>\n",
              "      <td>3.909113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>3.893000</td>\n",
              "      <td>3.514704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>3.511700</td>\n",
              "      <td>3.154520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>3.157400</td>\n",
              "      <td>2.825149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>2.835500</td>\n",
              "      <td>2.519859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>2.544500</td>\n",
              "      <td>2.247017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.280500</td>\n",
              "      <td>2.008363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>2.045700</td>\n",
              "      <td>1.794881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.839700</td>\n",
              "      <td>1.610898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.661300</td>\n",
              "      <td>1.452229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.507600</td>\n",
              "      <td>1.319788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.379800</td>\n",
              "      <td>1.211806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.274800</td>\n",
              "      <td>1.123166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.190400</td>\n",
              "      <td>1.052286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.125400</td>\n",
              "      <td>1.001979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.077800</td>\n",
              "      <td>0.966365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.047300</td>\n",
              "      <td>0.946022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=150, training_loss=4.6632652091979985, metrics={'train_runtime': 153.0709, 'train_samples_per_second': 3.724, 'train_steps_per_second': 0.98, 'total_flos': 154407995965440.0, 'train_loss': 4.6632652091979985, 'epoch': 30.0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dataset was very less (19) and epoch was small enough, its obvious the loss is high. however, we can see it decreasing. So the model is working.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "pbdl3-t9Bcyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##@ first saving the finetuned model and testing\n",
        "\n",
        "model.save_pretrained('./finetuned_mbart')\n",
        "tokenizer.save_pretrained('./finetuned_mbart')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_XYWcweFTnX",
        "outputId": "911e6cf4-8889-446a-8d4c-933911195426"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./finetuned_mbart/tokenizer_config.json',\n",
              " './finetuned_mbart/special_tokens_map.json',\n",
              " './finetuned_mbart/sentencepiece.bpe.model',\n",
              " './finetuned_mbart/added_tokens.json',\n",
              " './finetuned_mbart/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Time to test\n",
        "\n",
        "model_name= \"./finetuned_mbart\"\n",
        "\n",
        "tokenizer= MBart50TokenizerFast.from_pretrained(model_name)\n",
        "model= MBartForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "3WKpwodUFtZH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_after(input_text):\n",
        "\n",
        "    source_lang=\"en_XX\"\n",
        "    target_lang=\"ne_NP\"\n",
        "    # Set the tokenizer's source language\n",
        "    tokenizer.src_lang = source_lang\n",
        "\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to('cpu')\n",
        "\n",
        "    # Generate translation with the target language token forced at the beginning\n",
        "    translated_tokens = model.generate(\n",
        "        **inputs,\n",
        "        forced_bos_token_id=tokenizer.lang_code_to_id[target_lang]\n",
        "    )\n",
        "\n",
        "    # Decode the generated tokens to get the translated text\n",
        "    return tokenizer.decode(translated_tokens[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "_stPRopiMeFT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text= '''hey Bae! what's up?\n",
        "\n",
        " I Bet you are fine.\n",
        "\n",
        " How's your fam?\n",
        " '''\n",
        "\n",
        "translated_after_text = translate_after(input_text)\n",
        "\n",
        "print(translated_after_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj0VqY0qGH3o",
        "outputId": "0d87ef22-2c21-4489-8499-c5d4403e805b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡§π‡•á ‡§™‡•ç‡§∞‡•á‡§Æ‡•Ä! ‡§ï‡•á ‡§≠‡§á‡§∞‡§π‡•á‡§õ? ‡§Æ ‡§™‡§ï‡•ç‡§ï‡§æ ‡§§‡§ø‡§Æ‡•Ä ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§õ‡•å‡•§ ‡§§‡§ø‡§Æ‡•ç‡§∞‡§æ ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞‡§Æ‡§æ ‡§ï‡•á ‡§≠‡§á‡§∞‡§π‡•á‡§õ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üòµ‚Äçüí´ Well it's working I guess ü§∑‚Äç‚ôÇÔ∏è"
      ],
      "metadata": {
        "id": "2Lh4qXpKNA2B"
      }
    }
  ]
}