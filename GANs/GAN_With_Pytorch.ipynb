{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Firojpaudel/GenAI-Chronicles/blob/main/GANs/GAN_With_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Trying to implement GAN using PyTorch**: MNIST Dataset\n",
        "---"
      ],
      "metadata": {
        "id": "YrVMe8W0PCPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_lr_finder"
      ],
      "metadata": {
        "id": "lrLPoxws1V1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7ewqc_1REcDT"
      },
      "outputs": [],
      "source": [
        "##@ Imports\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch_lr_finder import LRFinder\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Hyperparameters and configs\n",
        "n_epochs = 50\n",
        "batch_size = 64\n",
        "latent_dim = 100\n",
        "img_size= 28\n",
        "b1= 0.5\n",
        "b2= 0.999\n",
        "lr= 0.001 #Initial testing learning rate\n",
        "channels = 1\n",
        "sample_interval = 400\n",
        "\n",
        "## Image shape\n",
        "image_shape = (channels, img_size, img_size)"
      ],
      "metadata": {
        "id": "WkYX-DU_1fWD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Testing for GPU\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "cuda"
      ],
      "metadata": {
        "id": "vDCmbOmU0lGy",
        "outputId": "69d4271a-3b2d-498c-895d-924bec5427dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Creating the directory for saving the images\n",
        "os.makedirs(\"Generated_images\", exist_ok= True)"
      ],
      "metadata": {
        "id": "8Cf8m3l52bCk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Creating the Generator"
      ],
      "metadata": {
        "id": "3PZ_TThRr3yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##@ First lets create the generator nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, latent_dim, img_shape):\n",
        "    super(Generator, self).__init__()\n",
        "    self.img_shape = img_shape\n",
        "\n",
        "    def block(in_features, out_features, normalize= True):\n",
        "      layers = [nn.Linear(in_features, out_features)]\n",
        "      if normalize:\n",
        "        layers.append(nn.BatchNorm1d(out_features, momentum=0.8))\n",
        "      layers.append(nn.LeakyReLU(0.2, inplace= True))\n",
        "      return layers\n",
        "\n",
        "    self.model= nn.Sequential(\n",
        "        *block(latent_dim, 128, normalize = False),\n",
        "        *block(128, 256),\n",
        "        *block(256, 512),\n",
        "        *block(512, 1024),\n",
        "        nn.Linear(1024, int(np.prod(img_shape))),  #Trying to match with the dimension of the image and then we apply the activation function\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, z):\n",
        "    img = self.model(z)\n",
        "    return img.view(img.size(0), *self.img_shape)"
      ],
      "metadata": {
        "id": "j4ClbOZpVlnY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Explaining the code above:** _Generator_\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "RNbTwJ1fl2MS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, so first lets explain the block function and the need for it:\n",
        "\n",
        "If we did not use block function the code snippet for `self.model` would look like:\n",
        "\n",
        "```python\n",
        " self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),  # First layer\n",
        "            nn.LeakyReLU(0.2, inplace=True),  # Activation\n",
        "            nn.Linear(128, 256),  # Second layer\n",
        "            nn.BatchNorm1d(256, momentum=0.8),  # Batch normalization\n",
        "            nn.LeakyReLU(0.2, inplace=True),  # Activation\n",
        "            nn.Linear(256, 512),  # Third layer\n",
        "            nn.BatchNorm1d(512, momentum=0.8),  # Batch normalization\n",
        "            nn.LeakyReLU(0.2, inplace=True),  # Activation\n",
        "            nn.Linear(512, 1024),  # Fourth layer\n",
        "            nn.BatchNorm1d(1024, momentum=0.8),  # Batch normalization\n",
        "            nn.LeakyReLU(0.2, inplace=True),  # Activation\n",
        "            nn.Linear(1024, int(np.prod(img_shape))),  # Output layer\n",
        "            nn.Tanh()  # Final activation function\n",
        "        )\n",
        "\n",
        "```\n",
        "\n",
        "which is obviously very tough to handle. So we just created the function `\"block\"` which opens up in the model created.\n",
        "\n",
        "> **_Note:_** \\\n",
        "When you call `*block(...)` inside `nn.Sequential`, the asterisk _unpacks the list of layers returned by the block function_. Without the asterisk, the code would pass the whole list as a single element, which would cause an error.\n",
        "\n",
        "The same goes for ` *self.img_shape`. It's just unpacking the image dimensions\n",
        "\n"
      ],
      "metadata": {
        "id": "wzJlV7qpmHMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Creating the discriminator"
      ],
      "metadata": {
        "id": "Cgxvyizurowa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Now Creating the discriminator:\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, img_shape):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.model= nn.Sequential(\n",
        "        nn.Linear(int(np.prod(img_shape)), 512),\n",
        "        nn.LeakyReLU(0.2, inplace= True),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.LeakyReLU(0.2, inplace= True),\n",
        "        nn.Linear(256, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    def forward(self, img):\n",
        "      img_flat = img.view(img.size(0), -1)\n",
        "      return self.model(img_flat)"
      ],
      "metadata": {
        "id": "y2t53PSjnqsq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Explaining the code above:** _Discriminator_\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WTkXfWYPv-Tj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, so here, its pretty straight forward. We create the model which has the final activation funciton of `sigmoid` and this simply classifies as real or fake.\n",
        "\n",
        "> 1 being the absolute real image classification and 0 being the absolute fake image classification\n",
        "\n",
        "Also lets discuss about the `img.view`:\n",
        "\n",
        "Explaining with the example case,\n",
        "\n",
        "Let's say we have a batch of **3 RGB images, each of size 64x64**:\n",
        "\n",
        "- `img.shape` would be $(3, 3, 64, 64)$ ie. $(\\text{batch_size}, \\text{channels}, \\text{height}, \\text{width})$.\n",
        "\n",
        "`img.view(img.size(0), -1)` would do the following:\n",
        "- `img.size(0)` is 3 (the batch size).\n",
        "- `-1` calculates $3 * 64 * 64 = 12288$.\n",
        "\n",
        "The resulting shape would be (3, 12288)"
      ],
      "metadata": {
        "id": "yGdMmqi6wFH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Initialize the Generator and Discriminator"
      ],
      "metadata": {
        "id": "wBzOZV1Q3YZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator= Generator(latent_dim= latent_dim, img_shape= image_shape)\n",
        "discriminator = Discriminator(img_shape=image_shape)"
      ],
      "metadata": {
        "id": "8FE4ewQ73gbL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Moving the models to GPU if available"
      ],
      "metadata": {
        "id": "lxYXx4BI3LhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if cuda:\n",
        "  generator.cuda()\n",
        "  discriminator.cuda()"
      ],
      "metadata": {
        "id": "UetyvihQ3T57"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Defining the Loss Function"
      ],
      "metadata": {
        "id": "_a8L6AVTwes5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Loss Function\n",
        "\n",
        "adversarial_loss = torch.nn.BCELoss() #The adversarial loss is simply Binary Cross Entropy Loss\n",
        "if cuda:\n",
        "  adversarial_loss.cuda()"
      ],
      "metadata": {
        "id": "mpGWNNoOyb7y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Optimizers for Generator and Discriminator"
      ],
      "metadata": {
        "id": "Tfeov8BU0RQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_Gen = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "optimizer_Dis = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))"
      ],
      "metadata": {
        "id": "Lqn7HHUs5MgC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Preping the data"
      ],
      "metadata": {
        "id": "BbxC44Jc65qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader= DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"./data/MNIST\",\n",
        "        train= True,\n",
        "        download= True,\n",
        "        transform= transforms.Compose([\n",
        "            transforms.Resize(img_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5], [0.5])  #Normalizing to [-1, 1]\n",
        "        ])\n",
        "    ),\n",
        "    batch_size= batch_size,\n",
        "    shuffle= True\n",
        ")"
      ],
      "metadata": {
        "id": "eGJcO5Fz6-Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##@ Trying to find a good learning rate\n",
        "lr_finder = LRFinder(generator, optimizer_Gen, adversarial_loss, device= \"cuda\" if cuda else \"cpu\")\n",
        "\n",
        "# Create a sample batch of random noise to use with the LRFinder\n",
        "noise = torch.randn(batch_size, latent_dim, device=lr_finder.device)\n",
        "\n",
        "# Instead of iterating through the dataloader, we'll use a custom iterator:\n",
        "class NoiseIterator:\n",
        "    def __init__(self, noise):\n",
        "        self.noise = noise\n",
        "    def __next__(self):\n",
        "        return self.noise, torch.zeros(batch_size, device=self.noise.device)  # Dummy labels\n",
        "    def get_batch(self):\n",
        "        return next(self)\n",
        "\n",
        "noise_iterator = NoiseIterator(noise)\n",
        "\n",
        "# Now call range_test with the noise_iterator:\n",
        "lr_finder.range_test(noise_iterator, end_lr=1, num_iter=100)\n",
        "lr_finder.plot()\n",
        "lr_finder.reset()"
      ],
      "metadata": {
        "id": "SXu1MFEN6VBz",
        "outputId": "020ad588-d683-4e32-d09e-5b58f2e02df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Optimizer already has a scheduler attached to it",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-42cd4533bd6f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##@ Trying to find a good learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_Gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madversarial_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create a sample batch of random noise to use with the LRFinder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_lr_finder/lr_finder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, optimizer, criterion, device, memory_cache, cache_dir, amp_backend, amp_config, grad_scaler)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Check if the optimizer is already attached to a scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_for_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_lr_finder/lr_finder.py\u001b[0m in \u001b[0;36m_check_for_scheduler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"initial_lr\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimizer already has a scheduler attached to it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking_transfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Optimizer already has a scheduler attached to it"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyONCALyU3zJtSRGza6J91YS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}