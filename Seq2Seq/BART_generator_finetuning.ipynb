{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Finetuning** `facebook/bart-large` **on** `lmsys/chatbot_arena_conversations` **dataset**\n\n---","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# !pip install datasets transformers torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:09:34.335491Z","iopub.execute_input":"2025-01-11T13:09:34.335853Z","iopub.status.idle":"2025-01-11T13:09:34.340168Z","shell.execute_reply.started":"2025-01-11T13:09:34.335788Z","shell.execute_reply":"2025-01-11T13:09:34.339276Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nmodel_name= \"facebook/bart-large\"\n\nmodel= AutoModelForSeq2SeqLM.from_pretrained(model_name)\ntokenizer= AutoTokenizer.from_pretrained(model_name, clean_up_tokenization_spaces = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:09:34.349676Z","iopub.execute_input":"2025-01-11T13:09:34.349942Z","iopub.status.idle":"2025-01-11T13:09:49.720641Z","shell.execute_reply.started":"2025-01-11T13:09:34.349921Z","shell.execute_reply":"2025-01-11T13:09:49.719887Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f428ab669aa4e9197febe76a79c41db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a170881d06484a04b58f835fc99b8f18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92449f29e55b4fb18dc7b6804eb669cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f4b3c86ba6341558ef54fcfa4e54915"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fdb5a3fed1749ee9adae946f5ebfa1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3be10ee55ab046149f409f4c3c23a33b"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Ensure model is on CUDA (GPU)\ndevice = model.device\ntexts = [\"This is an example sentence.\", \"Another sentence to check dimensions.\"]\n# Tokenize and move inputs to the same device as the model\ninputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n\n# Move input tensors to the correct device (same as model)\ninputs = {key: value.to(device) for key, value in inputs.items()}\n\n# Forward pass with output_hidden_states=True to include decoder hidden states\noutputs = model(**inputs, output_hidden_states=True)\n\n# Check output shapes\nprint(f\"Logits shape: {outputs.logits.shape}\")\nprint(f\"Encoder hidden states shape: {outputs.encoder_last_hidden_state.shape}\")\nprint(f\"Decoder hidden states shape: {outputs.decoder_hidden_states[0].shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:13:17.720342Z","iopub.execute_input":"2025-01-11T13:13:17.720638Z","iopub.status.idle":"2025-01-11T13:13:17.763312Z","shell.execute_reply.started":"2025-01-11T13:13:17.720616Z","shell.execute_reply":"2025-01-11T13:13:17.762070Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-b6fca15449cc>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Move input tensors to the correct device (same as model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Forward pass with output_hidden_states=True to include decoder hidden states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-b6fca15449cc>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Move input tensors to the correct device (same as model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Forward pass with output_hidden_states=True to include decoder hidden states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}],"execution_count":22},{"cell_type":"markdown","source":"So, before I access the dataset, the dataset is a gated dataset. i.e., it doesnot allow to access until and unless users have authorized and agreed to terms and conditions. Hence Huggingface login is required.","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"Hugging_face\")\nsecret_value_1 = user_secrets.get_secret(\"wandb_api_key\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:09:49.726953Z","iopub.execute_input":"2025-01-11T13:09:49.727237Z","iopub.status.idle":"2025-01-11T13:09:49.940136Z","shell.execute_reply.started":"2025-01-11T13:09:49.727210Z","shell.execute_reply":"2025-01-11T13:09:49.939384Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:09:49.941171Z","iopub.execute_input":"2025-01-11T13:09:49.941460Z","iopub.status.idle":"2025-01-11T13:09:49.989989Z","shell.execute_reply.started":"2025-01-11T13:09:49.941430Z","shell.execute_reply":"2025-01-11T13:09:49.989131Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"lmsys/chatbot_arena_conversations\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:09:49.990907Z","iopub.execute_input":"2025-01-11T13:09:49.991231Z","iopub.status.idle":"2025-01-11T13:09:52.837746Z","shell.execute_reply.started":"2025-01-11T13:09:49.991201Z","shell.execute_reply":"2025-01-11T13:09:52.837119Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4d44aea1b014dc5b36d625f98787073"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-cced8514c7ed782a.parquet:   0%|          | 0.00/41.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4f167e9c5e1411681c44440cc082930"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/33000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b22836ae5014d2eb49aed330224e0eb"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:09:52.838476Z","iopub.execute_input":"2025-01-11T13:09:52.838885Z","iopub.status.idle":"2025-01-11T13:09:52.843928Z","shell.execute_reply.started":"2025-01-11T13:09:52.838848Z","shell.execute_reply":"2025-01-11T13:09:52.843174Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['question_id', 'model_a', 'model_b', 'winner', 'judge', 'conversation_a', 'conversation_b', 'turn', 'anony', 'language', 'tstamp', 'openai_moderation', 'toxic_chat_tag'],\n        num_rows: 33000\n    })\n})"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(ds['train'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:09:52.845023Z","iopub.execute_input":"2025-01-11T13:09:52.845358Z","iopub.status.idle":"2025-01-11T13:10:01.033708Z","shell.execute_reply.started":"2025-01-11T13:09:52.845328Z","shell.execute_reply":"2025-01-11T13:10:01.033042Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df['language'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:10:01.039502Z","iopub.execute_input":"2025-01-11T13:10:01.039759Z","iopub.status.idle":"2025-01-11T13:10:01.058679Z","shell.execute_reply.started":"2025-01-11T13:10:01.039737Z","shell.execute_reply":"2025-01-11T13:10:01.057803Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array(['English', 'unknown', 'French', 'Latin', 'Arabic', 'Italian',\n       'Latvian', 'Portuguese', 'Japanese', 'German', 'Spanish',\n       'Chinese', 'Russian', 'Slovak', 'Turkish', 'Akan', 'Danish',\n       'Uzbek', 'Esperanto', 'Scots', 'Indonesian', 'Hebrew', 'Dutch',\n       'Korean', 'Corsican', 'Wolof', 'Waray', 'Luxembourgish',\n       'Bulgarian', 'Serbian', 'Czech', 'Catalan', 'Manx', 'Swedish',\n       'Malagasy', 'Polish', 'Norwegian', 'Interlingua', 'Oromo',\n       'Tswana', 'Finnish', 'Maori', 'Tsonga', 'Romanian', 'Bislama',\n       'Welsh', 'Xhosa', 'Galician', 'Malay', 'Persian', 'Vietnamese',\n       'zzp', 'Hawaiian', 'Aymara', 'Norwegian Nynorsk', 'Afrikaans',\n       'Icelandic', 'Ukrainian', 'Occitan', 'Hungarian', 'Thai',\n       'Lithuanian', 'Croatian', 'Quechua', 'Haitian Creole',\n       'Western Frisian', 'Interlingue', 'Somali', 'Slovenian', 'Afar',\n       'Irish', 'Kalaallisut', 'Volapük', 'Fijian', 'Sanskrit',\n       'Estonian', 'Basque', 'Hmong', 'Macedonian', 'Kinyarwanda',\n       'Bangla', 'Southern Sotho', 'Tatar', 'Sundanese', 'Greek',\n       'Guarani', 'Klingon', 'Shona', 'Hindi', 'Maltese', 'Ganda',\n       'Swahili', 'Cebuano', 'Tigrinya', 'Faroese', 'Yoruba'],\n      dtype=object)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"##@ First lets filter out the 'English' ones only:\n\ndf_eng = df[df['language'] == 'English']\n\ndf_eng['language'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:10:01.060105Z","iopub.execute_input":"2025-01-11T13:10:01.060413Z","iopub.status.idle":"2025-01-11T13:10:05.024441Z","shell.execute_reply.started":"2025-01-11T13:10:01.060392Z","shell.execute_reply":"2025-01-11T13:10:05.023509Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array(['English'], dtype=object)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"df_eng['conversation_a'][2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:10:05.025429Z","iopub.execute_input":"2025-01-11T13:10:05.025736Z","iopub.status.idle":"2025-01-11T13:10:05.032463Z","shell.execute_reply.started":"2025-01-11T13:10:05.025706Z","shell.execute_reply":"2025-01-11T13:10:05.031800Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[{'content': 'Fuji vs. Nikon, which is better?', 'role': 'user'},\n {'content': 'Both Fuji and Nikon are popular camera brands that offer a wide range of cameras for different types of photography. It really depends on your specific needs and preferences as to which brand is \"better\" for you.\\n\\nFujifilm is known for its high image quality, especially in the areas of color accuracy and dynamic range. Many photographers also appreciate the company\\'s focus on ergonomics and the overall user experience of its cameras. Additionally, Fujifilm has a loyal following among enthusiasts and professional photographers, thanks to its commitment to film photography and its high-end mirrorless cameras.\\n\\nNikon, on the other hand, is known for its advanced autofocus system and image stabilization technology, as well as its high-end cameras and lenses. Nikon also has a wide selection of cameras and lenses to choose from, including both DSLR and mirrorless options.\\n\\nUltimately, it\\'s difficult to say which brand is \"better\" without knowing more about your specific needs and preferences. It might be helpful to research both brands further and try out a few different models before making a decision.',\n  'role': 'assistant'}]"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"df_eng['conversation_b'][2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:10:05.033268Z","iopub.execute_input":"2025-01-11T13:10:05.033538Z","iopub.status.idle":"2025-01-11T13:10:05.044538Z","shell.execute_reply.started":"2025-01-11T13:10:05.033510Z","shell.execute_reply":"2025-01-11T13:10:05.043848Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[{'content': 'Fuji vs. Nikon, which is better?', 'role': 'user'},\n {'content': \"This is a subjective question and the answer depends on the individual preferences and needs. Both Fujifilm and Nikon are well-known for their high-quality cameras, and the choice between the two ultimately depends on the user's personal preferences and needs.\\n\\nSome factors to consider when deciding between a Fuji and a Nikon camera include:\\n\\n1. Image quality: Fuji cameras are known for their high-quality images, with a distinctive film-like quality. Nikon cameras are also notable for their image quality, but they may not offer the same level of sharpness and color accuracy as Fuji cameras.\\n\\n2. Focusing: Fuji cameras are known for their fast and precise autofocus, while Nikon cameras tend to have a slower and more manual focus system.\\n\\n3. Image size: Fuji cameras are known for their wide range of photo sizes, from small compacts to large-format cameras. Nikon cameras are also capable of producing high-quality images, but they may not be as versatile as Fuji cameras.\\n\\n4. User interface: Fuji cameras have a user-friendly interface, with a simplified design that is easy to navigate. Nikon cameras may have a more complex interface, but they also offer a wealth of features and customization options.\\n\\nUltimately, the best camera for you will depend on your specific needs and preferences. If you're looking for a high-quality camera that offers a unique film-like experience, a Fuji camera may be the right choice for you. If you're looking for a camera that is easy to use and offers a wide range of photo sizes, a Nikon camera may be the best choice.\",\n  'role': 'assistant'}]"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"Looks like this dataset has two conversations, \"a\" and \"b\".\n\nSo, during preprocessing, we could just use \"conversation_b\"'s user role content ie the questions and pass it to the inputs while targets would be the content from assistant role...","metadata":{}},{"cell_type":"code","source":"##@ Preprocessing_function \n\ndef preprocess_function(data):\n\n    inputs= [\n        \" \".join([entry['content'] for entry in conv if entry['role'] == 'user'])\n        for conv in data['conversation_b']\n    ]\n\n    targets= [\n        \" \".join([entry['content'] for entry in conv if entry['role'] == 'assistant'])\n        for conv in data['conversation_b']\n    ]\n    \n    ## Tokenizing\n    model_inputs = tokenizer(inputs, max_length= 128, padding= \"max_length\", truncation= True)\n\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=1028, padding='max_length', truncation=True)\n\n    ## adding labels to inputs \n    model_inputs['labels'] = labels['input_ids']\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:10:05.045375Z","iopub.execute_input":"2025-01-11T13:10:05.045648Z","iopub.status.idle":"2025-01-11T13:10:05.057454Z","shell.execute_reply.started":"2025-01-11T13:10:05.045621Z","shell.execute_reply":"2025-01-11T13:10:05.056815Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"the `df_eng` was in pandas. Now for mapping we need to convert this back to hugging face dataset ","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\n\nhf_dataset = Dataset.from_pandas(df_eng, preserve_index= False)\n\nhf_dataset= hf_dataset.train_test_split(test_size=0.2)\n\ndataset_dict = DatasetDict({\n    'train': hf_dataset['train'], \n    'validation': hf_dataset['test']\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:10:05.058255Z","iopub.execute_input":"2025-01-11T13:10:05.058528Z","iopub.status.idle":"2025-01-11T13:10:06.089515Z","shell.execute_reply.started":"2025-01-11T13:10:05.058500Z","shell.execute_reply":"2025-01-11T13:10:06.088603Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"dataset_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:10:06.090396Z","iopub.execute_input":"2025-01-11T13:10:06.090685Z","iopub.status.idle":"2025-01-11T13:10:06.095783Z","shell.execute_reply.started":"2025-01-11T13:10:06.090657Z","shell.execute_reply":"2025-01-11T13:10:06.095035Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['question_id', 'model_a', 'model_b', 'winner', 'judge', 'conversation_a', 'conversation_b', 'turn', 'anony', 'language', 'tstamp', 'openai_moderation', 'toxic_chat_tag'],\n        num_rows: 23364\n    })\n    validation: Dataset({\n        features: ['question_id', 'model_a', 'model_b', 'winner', 'judge', 'conversation_a', 'conversation_b', 'turn', 'anony', 'language', 'tstamp', 'openai_moderation', 'toxic_chat_tag'],\n        num_rows: 5842\n    })\n})"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"tokenized_datasets = dataset_dict.map(preprocess_function, batched= True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:10:06.096448Z","iopub.execute_input":"2025-01-11T13:10:06.096738Z","iopub.status.idle":"2025-01-11T13:11:27.673628Z","shell.execute_reply.started":"2025-01-11T13:10:06.096706Z","shell.execute_reply":"2025-01-11T13:11:27.672890Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/23364 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfda62066f5d46d296fb9bcfa30fc995"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5842 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99baddabac4a4b5a8fcda6fc87feefa0"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments,DataCollatorForSeq2Seq\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    predict_with_generate=True,\n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:11:27.675454Z","iopub.execute_input":"2025-01-11T13:11:27.675711Z","iopub.status.idle":"2025-01-11T13:11:37.191725Z","shell.execute_reply.started":"2025-01-11T13:11:27.675688Z","shell.execute_reply":"2025-01-11T13:11:37.190881Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model= model,\n    args=training_args,\n    train_dataset=tokenized_datasets['train'],\n    eval_dataset=tokenized_datasets['validation'],\n    data_collator= data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:11:37.192540Z","iopub.execute_input":"2025-01-11T13:11:37.193182Z","iopub.status.idle":"2025-01-11T13:11:39.547943Z","shell.execute_reply.started":"2025-01-11T13:11:37.193156Z","shell.execute_reply":"2025-01-11T13:11:39.547250Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import wandb\nwandb.login(key= secret_value_1)\nwandb.init(project=\"Chatbot_\", name=\"version1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:11:39.548800Z","iopub.execute_input":"2025-01-11T13:11:39.549076Z","iopub.status.idle":"2025-01-11T13:11:52.644482Z","shell.execute_reply.started":"2025-01-11T13:11:39.549051Z","shell.execute_reply":"2025-01-11T13:11:52.643604Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfirojpaudel\u001b[0m (\u001b[33mfirojpaudel-madan-bhandari-memorial-college\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250111_131146-b59sdlrk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/firojpaudel-madan-bhandari-memorial-college/Chatbot_/runs/b59sdlrk' target=\"_blank\">version1</a></strong> to <a href='https://wandb.ai/firojpaudel-madan-bhandari-memorial-college/Chatbot_' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/firojpaudel-madan-bhandari-memorial-college/Chatbot_' target=\"_blank\">https://wandb.ai/firojpaudel-madan-bhandari-memorial-college/Chatbot_</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/firojpaudel-madan-bhandari-memorial-college/Chatbot_/runs/b59sdlrk' target=\"_blank\">https://wandb.ai/firojpaudel-madan-bhandari-memorial-college/Chatbot_/runs/b59sdlrk</a>"},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/firojpaudel-madan-bhandari-memorial-college/Chatbot_/runs/b59sdlrk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7ee8755572e0>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:11:52.645442Z","iopub.execute_input":"2025-01-11T13:11:52.645675Z","iopub.status.idle":"2025-01-11T13:11:55.517403Z","shell.execute_reply.started":"2025-01-11T13:11:52.645646Z","shell.execute_reply":"2025-01-11T13:11:55.516140Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1939\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2278\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3317\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3318\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3320\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/parallel_apply.py\", line 84, in _worker\n    output = module(*input, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\", line 1641, in forward\n    outputs = self.model(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\", line 1527, in forward\n    decoder_outputs = self.decoder(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\", line 1312, in forward\n    encoder_attention_mask = _prepare_4d_attention_mask_for_sdpa(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_attn_mask_utils.py\", line 452, in _prepare_4d_attention_mask_for_sdpa\n    return AttentionMaskConverter._expand_mask(mask=mask, dtype=dtype, tgt_len=tgt_len)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_attn_mask_utils.py\", line 186, in _expand_mask\n    return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)\nRuntimeError: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"],"ename":"RuntimeError","evalue":"Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/parallel_apply.py\", line 84, in _worker\n    output = module(*input, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\", line 1641, in forward\n    outputs = self.model(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\", line 1527, in forward\n    decoder_outputs = self.decoder(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\", line 1312, in forward\n    encoder_attention_mask = _prepare_4d_attention_mask_for_sdpa(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_attn_mask_utils.py\", line 452, in _prepare_4d_attention_mask_for_sdpa\n    return AttentionMaskConverter._expand_mask(mask=mask, dtype=dtype, tgt_len=tgt_len)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_attn_mask_utils.py\", line 186, in _expand_mask\n    return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)\nRuntimeError: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n","output_type":"error"}],"execution_count":20}]}